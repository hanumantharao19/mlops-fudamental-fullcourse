üèóÔ∏è 1. Where do we deploy machine learning models?
‚û§ Deployment Environments:

Cloud Platforms

AWS SageMaker, GCP Vertex AI, Azure ML

Offer managed infrastructure for training, deployment, scaling, and monitoring.

On-Premise Servers

Used when data privacy or cost constraints exist.

Docker + Kubernetes clusters are common setups.

Edge Devices

For IoT, mobile, or embedded systems (e.g., TensorFlow Lite, ONNX).

Hybrid Setup

Training on cloud + inference at edge or local servers.

‚úÖ MLOps Engineer Role:

Set up and manage deployment pipelines, ensure scalability, and monitor model performance post-deployment.

üîó 2. How do API services call the model?
‚û§ Steps:

Model is served as an API service

Using Flask / FastAPI / TensorFlow Serving / TorchServe.

The API exposes an endpoint like:

POST /predict


Accepts input JSON ‚Üí returns prediction JSON.

Client or application (web, mobile, backend) makes HTTP request to this endpoint.

API internally loads the model (from registry or storage) ‚Üí performs inference ‚Üí returns result.

‚úÖ MLOps Engineer Role:

Build & maintain the model API service.

Optimize for speed, load balancing, and scalability.

Manage containerization (Docker) and service orchestration (Kubernetes).

üîÑ 3. How do we deploy new versions of the model?
‚û§ Version Deployment Strategies:

Model Registry

Track model versions (v1, v2, v3...) using MLflow, DVC, or SageMaker Model Registry.

Deployment Pipelines

Automated CI/CD pipeline builds Docker image ‚Üí pushes ‚Üí deploys new version.

Versioning Techniques

Canary Deployment: Gradually roll out new version to a small % of users.

Blue-Green Deployment: Run two environments (old & new) ‚Üí switch traffic safely.

Shadow Deployment: New version runs in background for testing.

‚úÖ MLOps Engineer Role:

Ensure zero downtime, proper rollback plans, and performance validation for each new version.

‚öôÔ∏è 4. Who maintains model service and uptime?
‚û§ Responsible Teams:

MLOps Engineers: Handle model serving, deployment health, and automation.

Site Reliability Engineers (SREs): Focus on uptime, system reliability, monitoring, alerting.

DevOps Engineers: Support infrastructure, CI/CD, and cloud setup.

‚úÖ MLOps Engineer Role:

Continuously monitor model latency, prediction errors, and infrastructure health.

Use tools like Prometheus, Grafana, and ELK for uptime and performance dashboards.

Coordinate with SRE for 24√ó7 reliability and scalability.

üß™ 5. How do we manage experimental services and related infrastructure?
‚û§ Experiment Management Includes:

Tracking experiments: Hyperparameters, metrics, and results using MLflow / W&B.

Data versioning: Using DVC or Git-LFS to reproduce experiments.

Resource management: Using Kubernetes, Airflow, or Cloud AutoML to allocate compute.

Reproducibility: Store code, data, and model configuration under version control.

‚úÖ MLOps Engineer Role:

Build systems to track, compare, and reproduce experiments.

Automate infrastructure provisioning for new experiments.

Ensure experimental results can move easily to production-ready models.